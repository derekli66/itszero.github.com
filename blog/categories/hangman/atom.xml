<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: hangman | [Zero setLogger: self];]]></title>
  <link href="http://itszero.github.com/blog/categories/hangman/atom.xml" rel="self"/>
  <link href="http://itszero.github.com/"/>
  <updated>2014-03-01T18:25:27-05:00</updated>
  <id>http://itszero.github.com/</id>
  <author>
    <name><![CDATA[Zero Cho]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[(my way to) Write a Hangman AI]]></title>
    <link href="http://itszero.github.com/blog/2012/10/29/my-way-to-write-a-hangman-ai/"/>
    <updated>2012-10-29T20:17:00-04:00</updated>
    <id>http://itszero.github.com/blog/2012/10/29/my-way-to-write-a-hangman-ai</id>
    <content type="html"><![CDATA[<p>I was asked to write a hangman AI as a challenge last week. I was asked not to
leak the detail, so I will not post my solution here. However, the hangman
problem itself is a well-known problem, I would like to share some thoughts
that I used to build my hangman solver.</p>

<h2>Preface</h2>

<p>There is a <a href="http://en.wikipedia.org/wiki/Hangman_(game)">hangman</a> page provides detailed information for hangman
game. However, I would like to describe it in a shorter, more programmer&rsquo;s way.</p>

<h3>Input</h3>

<p>You will receive an serialized object containing following information:</p>

<ul>
<li><p>state: The state is a string that reveals your correctly guessed characters
in the string. For those unrevealed characters, a <code>_</code> is placed in those
positions. For example, say the answer is &ldquo;apple&rdquo; and you guessed <em>p</em>, the
state string will be <code>_pp__</code>. Please note that the state could contain
multiple words, a sentence.</p></li>
<li><p>remaining_guesses: How many times you can make a wrong guess before the game
is over.</p></li>
<li><p>status: It could be one of {<strong>WIN</strong>, <strong>ONGOING</strong>, <strong>LOSE</strong>}. The game will
start as <strong>ONGOING</strong>.  If you reveal all characters before you used up all
guesses, you <strong>WIN</strong> the game. If you make too many wrong guesses, you
<strong>LOSE</strong> the game.</p></li>
</ul>


<h3>Output</h3>

<p>For each game, you will start with a empty state. You must keep giving out a
character as a guess until the status is <strong>WIN</strong> or <strong>LOSE</strong>.</p>

<h2>Thoughts</h2>

<p>Before we talk about anything, I need to clarify one thing: I am not familiar
with NLP(Natural Language Processing) techniques. I might use some dumb way to
solve this problem, but, well, it&rsquo;s at least something that my intuition leads
me to.</p>

<h3>Initial Guess</h3>

<p>If the state is all unrevealed, I will do an initial guess. The initial guess
uses vowels, the famous a-e-i-o-u. However, I use a little variation here. I do
not guess the vowels in this order, I sort it by the frequency of characters
appearing in dictionary. I guess by e-i-o-u-a. The initial guess stops whenever
a character works, then we go to word attack mode.</p>

<h3>Word Attack</h3>

<p>Since I don&rsquo;t have any knowledge in the language model, I will launch a
word-based attack. In my implementation, I only attack one word at a time. It
is very important that we choose the right word to attack. If we pick the wrong
word to guess, the probability to produce a correct guess will decrease. First,
I assume that, in most cases, the word-to-be-attacked will be included in my
dictionary. If we don&rsquo;t make this assumption, it is hard to do optimization
since you have to assume you have no knowledge regarding the context.</p>

<h4>Which Word?</h4>

<p>The best word to attack, in my opinion, is the word having most characters
solved and having longest length as possible. Now, to decide it, the formula I
used is:</p>

<p></p>

<div class="mathjax">
$$
f_{cost}(w_i) = \frac{f_{unsolved}(w_i)}{f_{strlen}(w_i)^2}
$$
</div>


<p></p>

<p>The best word to attack will have smallest cost from this formula. It first
calculate the percentage of unsolved characters in the word, so the word with
most portion of its characters revealed now having the smallest cost now. However, say we have a
word <code>a_</code>, the word is now 50% solved but to finish the second character, you
only need one move. It sounds good, but it does not generate any <em>side-effect</em>.
Say now we have a word <code>co__ec__e__</code> and you already know the full word is
<code>correctness</code>. You can now confidently send answers <code>[r, t, n, s]</code>. You may
reveal characters in other words in the process, thus increase the overall
probability of making right guesses.</p>

<h4>The n-grams</h4>

<p><blockquote><p>In the fields of computational linguistics and probability, an n-gram is a<br/>contiguous sequence of n items from a given sequence of text or speech. An<br/>n-gram could be any combination of letters. However, the items in question can<br/>be phonemes, syllables, letters, words or base pairs according to the<br/>application. The n-grams typically are collected from a text or speech corpus.</p><footer><strong>Wikipedia <a href="http://en.wikipedia.org/wiki/N-gram">http://en.wikipedia.org/wiki/N-gram</a> N-gram</strong></footer></blockquote></p>

<p>Since I&rsquo;m not a NLP guy, I will just quote the definition of n-gram from
Wikipedia. In my solver, I use two type of n-grams: A bigram table and a
unigram table. Before I calculate those, I will filter the dictionary to a
smaller version by eliminating words using the current state and guessed words.
For example, the state of the word I&rsquo;m attacking is <code>a__le</code>, and I haven&rsquo;t
guessed <code>[p, z]</code>. I will generate a regular expression of <code>a[pz][pz]le</code> and
apply it on my dictionary. Then, I calculate those n-grams table in current
reduced context.</p>

<h5>Unigram table</h5>

<p>My usage for unigram is very simple. I merely calculate the frequency of a
characters shows in my dictionary.</p>

<h5>Bigram table</h5>

<p>The bigram I&rsquo;m trying to build is based on the connection for two continuous
characters. I will split each word into bigrams using the following ruby code:</p>

<p>`&ldquo;ruby
def bigram_split(str)
  &ldquo;^#{str}$&rdquo;.split(&rdquo;).each_cons(2).to_a
end</p>

<blockquote><blockquote><p>bigram_split(&ldquo;hello&rdquo;)
=> [[&ldquo;^&rdquo;, &ldquo;h&rdquo;], [&ldquo;h&rdquo;, &ldquo;e&rdquo;], [&ldquo;e&rdquo;, &ldquo;l&rdquo;], [&ldquo;l&rdquo;, &ldquo;l&rdquo;], [&ldquo;l&rdquo;, &ldquo;o&rdquo;], [&ldquo;o&rdquo;, &ldquo;$&rdquo;]]
```</p></blockquote></blockquote>

<p>I collect those bigrams and calculate the frequency for each of those showing
up among whole bigrams space for current dictionary.</p>

<h4>The Attack</h4>

<p>Now everything that we need before launching the attack is prepared, we can
start to work on a guess. The first step is to acquire bigrams from the word
state. The only bigrams we need is those with one of the character unsolved,
but not all unsolved. In a more direct way, what we need is <code>[*, '_'] ['_',
*]</code> but not <code>['_', '_']</code>. For those unsolved bigrams, I use the bigram table
I just calculated to get a count on how frequent of a character shows up after
or before a known character. I then sum the count for all bigrams in the word
state and pick the character with highest count as the guess. It&rsquo;s that simple.</p>

<h4>Falling back</h4>

<p>Well, sometimes you just don&rsquo;t have any clue. In that case, my program will
first falls back to attack on second best word and so on. If all words are
tried, but we still have no clue. I&rsquo;ll just fire a random guess using unigram
table. However, it is really a wild guess, the success rate of making a correct
guess using unigram table is not high.</p>

<h2>Future Work</h2>

<p>There are many ideas that can be implemented to improve my solution. Like
implementing a word bigrams to further weight the possibility of characters
bigrams could be useful, but it would require more research into NLP field. I
think it is really a fun challenge. If you got some spare time, try it!</p>
]]></content>
  </entry>
  
</feed>
